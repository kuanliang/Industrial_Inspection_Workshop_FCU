{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11412dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from monai import config\n",
    "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Activations, AddChannel, AsDiscrete, Compose, LoadImage, SaveImage, ScaleIntensity, EnsureType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eaf87aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.7.0+43.g7b1b772a\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+3fd9dcf\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "MONAI rev id: 7b1b772a4ad30c259696001a1a2380c52adffb65\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.2.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.0.2\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.1\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.3\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.11.3\n",
      "mlflow version: 1.20.2\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to tmp_evaluation (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "tempdir = 'tmp_evaluation'\n",
    "config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(5):\n",
    "    im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n",
    "    Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
    "    Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.png\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.png\")))\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "imtrans = Compose([LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "segtrans = Compose([LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "val_ds = ArrayDataset(images, imtrans, segs, segtrans)\n",
    "# sliding window inference for one image at every iteration\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n",
    "saver = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"seg\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74e0e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_array.pth\"))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfeabcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file written: /opt/monai/mnt/PyTorch/NoteBooks/GettingStarted/output/0/0_seg.png.\n",
      "file written: /opt/monai/mnt/PyTorch/NoteBooks/GettingStarted/output/1/1_seg.png.\n",
      "file written: /opt/monai/mnt/PyTorch/NoteBooks/GettingStarted/output/2/2_seg.png.\n",
      "file written: /opt/monai/mnt/PyTorch/NoteBooks/GettingStarted/output/3/3_seg.png.\n",
      "file written: /opt/monai/mnt/PyTorch/NoteBooks/GettingStarted/output/4/4_seg.png.\n",
      "evaluation metric: 0.9880849719047546\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        roi_size = (96, 96)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "        val_labels = decollate_batch(val_labels)\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        for val_output in val_outputs:\n",
    "            saver(val_output)\n",
    "    # aggregate the final mean dice result\n",
    "    print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "    # reset the status\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859768a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
